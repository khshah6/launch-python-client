# coding: utf-8

"""
    launch

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)  # noqa: E501

    The version of the OpenAPI document: 1.0.0
    Generated by: https://openapi-generator.tech
"""

import decimal  # noqa: F401
import functools  # noqa: F401
import io  # noqa: F401
import re  # noqa: F401
import typing  # noqa: F401
import uuid  # noqa: F401
from datetime import date, datetime  # noqa: F401

import frozendict  # noqa: F401
import typing_extensions  # noqa: F401

from launch.api_client import schemas  # noqa: F401


class GetLLMModelEndpointV1Response(schemas.DictSchema):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    class MetaOapg:
        required = {
            "inference_framework",
            "model_name",
            "num_shards",
            "inference_framework_image_tag",
            "name",
            "id",
            "source",
            "spec",
        }

        class properties:
            id = schemas.StrSchema

            @staticmethod
            def inference_framework() -> typing.Type["LLMInferenceFramework"]:
                return LLMInferenceFramework

            inference_framework_image_tag = schemas.StrSchema
            model_name = schemas.StrSchema
            name = schemas.StrSchema
            num_shards = schemas.IntSchema

            @staticmethod
            def source() -> typing.Type["LLMSource"]:
                return LLMSource

            @staticmethod
            def spec() -> typing.Type["GetModelEndpointV1Response"]:
                return GetModelEndpointV1Response

            __annotations__ = {
                "id": id,
                "inference_framework": inference_framework,
                "inference_framework_image_tag": inference_framework_image_tag,
                "model_name": model_name,
                "name": name,
                "num_shards": num_shards,
                "source": source,
                "spec": spec,
            }

    inference_framework: "LLMInferenceFramework"
    model_name: MetaOapg.properties.model_name
    num_shards: MetaOapg.properties.num_shards
    inference_framework_image_tag: MetaOapg.properties.inference_framework_image_tag
    name: MetaOapg.properties.name
    id: MetaOapg.properties.id
    source: "LLMSource"
    spec: "GetModelEndpointV1Response"

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id:
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["inference_framework"]) -> "LLMInferenceFramework":
        ...

    @typing.overload
    def __getitem__(
        self, name: typing_extensions.Literal["inference_framework_image_tag"]
    ) -> MetaOapg.properties.inference_framework_image_tag:
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["model_name"]) -> MetaOapg.properties.model_name:
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name:
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["num_shards"]) -> MetaOapg.properties.num_shards:
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["source"]) -> "LLMSource":
        ...

    @typing.overload
    def __getitem__(self, name: typing_extensions.Literal["spec"]) -> "GetModelEndpointV1Response":
        ...

    @typing.overload
    def __getitem__(self, name: str) -> schemas.UnsetAnyTypeSchema:
        ...

    def __getitem__(
        self,
        name: typing.Union[
            typing_extensions.Literal[
                "id",
                "inference_framework",
                "inference_framework_image_tag",
                "model_name",
                "name",
                "num_shards",
                "source",
                "spec",
            ],
            str,
        ],
    ):
        # dict_instance[name] accessor
        return super().__getitem__(name)

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["id"]) -> MetaOapg.properties.id:
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["inference_framework"]) -> "LLMInferenceFramework":
        ...

    @typing.overload
    def get_item_oapg(
        self, name: typing_extensions.Literal["inference_framework_image_tag"]
    ) -> MetaOapg.properties.inference_framework_image_tag:
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["model_name"]) -> MetaOapg.properties.model_name:
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["name"]) -> MetaOapg.properties.name:
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["num_shards"]) -> MetaOapg.properties.num_shards:
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["source"]) -> "LLMSource":
        ...

    @typing.overload
    def get_item_oapg(self, name: typing_extensions.Literal["spec"]) -> "GetModelEndpointV1Response":
        ...

    @typing.overload
    def get_item_oapg(self, name: str) -> typing.Union[schemas.UnsetAnyTypeSchema, schemas.Unset]:
        ...

    def get_item_oapg(
        self,
        name: typing.Union[
            typing_extensions.Literal[
                "id",
                "inference_framework",
                "inference_framework_image_tag",
                "model_name",
                "name",
                "num_shards",
                "source",
                "spec",
            ],
            str,
        ],
    ):
        return super().get_item_oapg(name)

    def __new__(
        cls,
        *_args: typing.Union[
            dict,
            frozendict.frozendict,
        ],
        inference_framework: "LLMInferenceFramework",
        model_name: typing.Union[
            MetaOapg.properties.model_name,
            str,
        ],
        num_shards: typing.Union[
            MetaOapg.properties.num_shards,
            decimal.Decimal,
            int,
        ],
        inference_framework_image_tag: typing.Union[
            MetaOapg.properties.inference_framework_image_tag,
            str,
        ],
        name: typing.Union[
            MetaOapg.properties.name,
            str,
        ],
        id: typing.Union[
            MetaOapg.properties.id,
            str,
        ],
        source: "LLMSource",
        spec: "GetModelEndpointV1Response",
        _configuration: typing.Optional[schemas.Configuration] = None,
        **kwargs: typing.Union[
            schemas.AnyTypeSchema,
            dict,
            frozendict.frozendict,
            str,
            date,
            datetime,
            uuid.UUID,
            int,
            float,
            decimal.Decimal,
            None,
            list,
            tuple,
            bytes,
        ],
    ) -> "GetLLMModelEndpointV1Response":
        return super().__new__(
            cls,
            *_args,
            inference_framework=inference_framework,
            model_name=model_name,
            num_shards=num_shards,
            inference_framework_image_tag=inference_framework_image_tag,
            name=name,
            id=id,
            source=source,
            spec=spec,
            _configuration=_configuration,
            **kwargs,
        )


from launch.api_client.model.get_model_endpoint_v1_response import (
    GetModelEndpointV1Response,
)
from launch.api_client.model.llm_inference_framework import (
    LLMInferenceFramework,
)
from launch.api_client.model.llm_source import LLMSource
